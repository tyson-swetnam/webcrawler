# AI News Crawler Environment Configuration
# Copy this file to .env and fill in your actual values

# Application Settings
APP_NAME=AI News Crawler
DEBUG=false
LOG_LEVEL=INFO

# Database Configuration
DATABASE_URL=postgresql://crawler:your_password_here@localhost:5432/ai_news_crawler
DATABASE_POOL_SIZE=10
REDIS_URL=redis://localhost:6379/0

# AI API Keys
# Get your Claude API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Get your OpenAI API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-key-here

# AI Model Configuration
# Claude Haiku for fast, cost-effective analysis
CLAUDE_MODEL=claude-haiku-4-5-20251001
# Claude Haiku for fast processing and initial filtering
CLAUDE_HAIKU_MODEL=claude-haiku-4-5-20251001
# OpenAI model for additional validation
OPENAI_MODEL=gpt-5-search-api-2025-10-14
# Token limits
MAX_AI_TOKENS=1024
MAX_HAIKU_TOKENS=512

# Web Crawling Configuration
MAX_CONCURRENT_REQUESTS=8
CRAWL_DELAY=1.0
USER_AGENT=AI-News-Crawler/1.0 (Research; +https://github.com/yourorg/ai-news-crawler)
REQUEST_TIMEOUT=30

# University Sources Configuration
# Options: legacy, r1, top_public, top_universities, meta_news, all
# Use 'all' to monitor all university lists simultaneously (recommended)
UNIVERSITY_SOURCE_TYPE=all
UNIVERSITY_LIST_PATH=crawler/config/universities.json

# Source Preferences
# Prefer AI-specific tag URLs (e.g., /topic/artificial-intelligence) over general news URLs
PREFER_AI_TAG_URLS=true
# Include meta news services (Chronicle, Inside Higher Ed, etc.)
INCLUDE_META_NEWS=false
# Use RSS feeds instead of HTML crawling when available (more efficient)
USE_RSS_FEEDS=true

# Slack Notifications
# Create a Slack webhook at: https://api.slack.com/messaging/webhooks
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
ENABLE_SLACK_NOTIFICATIONS=true

# Email Notifications
EMAIL_FROM=crawler@yourdomain.com
EMAIL_TO=["alerts@yourdomain.com","research@yourdomain.com"]
SMTP_HOST=smtp.gmail.com
SMTP_PORT=465
# For Gmail, use an app password: https://support.google.com/accounts/answer/185833
SMTP_PASSWORD=your-app-password-here
SMTP_USE_SSL=true
ENABLE_EMAIL_NOTIFICATIONS=true

# Scheduling
RUN_DAILY_AT=00:00
LOOKBACK_DAYS=1

# Content Filtering
MIN_ARTICLE_LENGTH=100
# Only process articles published within the last 7 days (recent news only)
MAX_ARTICLE_AGE_DAYS=7

# Performance Tuning
MAX_ARTICLES_PER_RUN=1000
AI_ANALYSIS_BATCH_SIZE=5

# Feature Flags
ENABLE_AI_ANALYSIS=true

# Logging
LOG_FILE_PATH=/var/log/ai-news-crawler/crawler.log
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=5
